{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/ARCO.jpeg\" width=800 alt=\"Project Pythia Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis-Ready Cloud-Optimized Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook, we will work on understanding the main concepts of creating ARCO datasets for the Geosciences. \n",
    "1. Analysis-Ready datasets\n",
    "1. Cloud-Optimized datasets\n",
    "2. Fair principles\n",
    "1. Zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Xarray](https://foundations.projectpythia.org/core/xarray.html) | Necessary |  Basic features |\n",
    "| [Radar Cookbook](https://projectpythia.org/radar-cookbook/README.html) | Necessary |  Radar basics |\n",
    "|[Intro to Zarr](https://zarr.readthedocs.io/en/stable/tutorial.html)| Necessary | Zarr basics\n",
    "\n",
    "- **Time to learn**: 30 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "from glob import glob\n",
    "import xradar as xd\n",
    "import matplotlib.pyplot as plt\n",
    "import cmweather\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "from xarray.core.datatree import DataTree\n",
    "from zarr.errors import ContainsGroupError  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analys-Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis-Ready data is a concept that emphasizes the preparation and structuring of datasets to be immediately usable for analysis. In the CrowdFlower Data Science Report 2016, the \"How Data Scientists Spend Their Time\" figure illustrates the distribution of time that data scientists allocate to various tasks. The figure highlights that the majority of a data scientist's time is dedicated to **preparing** and **cleaning data** (~80%), which is often considered the most time-consuming and critical part of the data science workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/AR.jpeg\" width=400 alt=\"Project Pythia Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s how AR caters to various aspects:\n",
    "\n",
    "* Datasets instead of data files\n",
    "* Pre-processed datasets, ensuring it is clean and well-organized\n",
    "* Dataset enriched with comprehensive metadata\n",
    "* Curated and cataloged\n",
    "* Facilitates a more efficient and accurate analysis\n",
    "* More time for fun (science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cloud-Optimized\n",
    "\n",
    "NetCDF/Raw radar data formats are not cloud optimized. Other formats, like Zarr, aim to make accessing and reading data from the cloud fast and painless. Cloud-Optimized data is structured for efficient storage, access, and processing in cloud environments.\n",
    "\n",
    "![Move to cloud diagram](../images/cloud-move.png)\n",
    "\n",
    "Cloud-Optimized leverages scalable formats and parallel processing capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAIR data\n",
    "\n",
    "FAIR data adheres to principles that ensure it is Findable, Accessible, Interoperable, and Reusable. These guidelines promote data sharing, collaboration, and long-term usability across various platforms and disciplines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![fair](../images/fair-data-principles.jpg) -->\n",
    "<img src=\"../images/fair-data-principles.jpg\" width=600 alt=\"Fair\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"FAIR sharing of data is beneficial for both data producers and consumers. Consumers gain access to interesting datasets that would otherwise be out of reach. Producers get citations to their work, when consumers publish their derivative work. OME-Zarr is the technology basis for enabling effective FAIR sharing of large image datasets.\" [Zarr illustrations](https://github.com/zarr-developers/zarr-illustrations-falk-2022?tab=readme-ov-file)\n",
    "\n",
    "<img src=\"../images/fair-reuse-300dpi.png\" width=400 alt=\"Fair\"></img>\n",
    "\n",
    "Courtesy: [Zarr illustrations](https://github.com/zarr-developers/zarr-illustrations-falk-2022?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zarr is a flexible and efficient format for storing large, chunked, compressed, multi-dimensional arrays, enabling easy and scalable data access in both local and cloud environments. It supports parallel processing and is widely used in scientific computing for handling large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/monolithic-vs-chunked-1200dpi.png\" width=400 alt=\"zarr\"></img>\n",
    "\n",
    "Courtesy: [Zarr illustrations](https://github.com/zarr-developers/zarr-illustrations-falk-2022?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCO Radar data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leveraging the Climate and Forecast (CF) format-based FM301 hierarchical tree structure, endorsed by the World Meteorological Organization (WMO), and Analysis-Ready Cloud-Optimized (ARCO) formats, we developed an open data model to arrange, manage, and store radar data in cloud-storage buckets efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CfRadial2.1/FM301 standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xradar employs `xarray.DataTree` objects to organize radar sweeps within a single hierachical structure, where each sweep is an `xarray.Dataset` containing relevant metadata and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/CfRadial2.1.svg\" width=500 alt=\"xradar\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this hierarchical-datatree looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to Pythi s3 Bucket\n",
    "URL = 'https://js2.jetstream-cloud.org:8001/'\n",
    "path = f'pythia/radar/erad2024'\n",
    "\n",
    "fs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n",
    "\n",
    "# C-band radar files\n",
    "path = \"pythia/radar/erad2024/20240522_MeteoSwiss_ARPA_Lombardia/Data/Cband/*.nc\"\n",
    "radar_files = fs.glob(path)\n",
    "radar_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files locally\n",
    "local_files = [\n",
    "    fsspec.open_local(\n",
    "        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n",
    "    )\n",
    "    for i in radar_files[:5]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open one of this `nc` files using `xradar.io.open_cfradial1_datree` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = xd.io.open_cfradial1_datatree(local_files[0])\n",
    "display(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our first ARCO dataset using `.to_zarr` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_zarr(\"radar.zarr\", consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that a new `Zarr` store is created (`Object storage`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is stored locally, but could be stored in a Bucket on the cloud. Let's open it back using `Xarray.backends.api.open_datatree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_back = xr.backends.api.open_datatree(\n",
    "    \"radar.zarr\", \n",
    "    consolidated=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(dt_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radar data time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating `xradar.DataTree` objects along a temporal dimension is a great approach to create a more organized and comprehensive dataset. By doing so, you can maintain a cohesive dataset that is both easier to manage and more meaningful for temporal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use our local files\n",
    "len(local_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an ARCO dataset, we need to ensure that all radar volumes are properly aligned. To achieve this, we developed the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_angle(ds: xr.Dataset, tolerance: float=None, **kwargs) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    This function reindex the radar azimuth angle to make all sweeps starts and end at the same angle\n",
    "    @param ds: xarray dataset containing and xradar object\n",
    "    @param tolerance: Tolerance for interpolation between azimuth angles. \n",
    "                      Defaul, the radar azimuth angle resolution.\n",
    "    @return: azimuth reindex xarray dataset\n",
    "    \"\"\"\n",
    "    ds[\"time\"] = ds.time.load() \n",
    "    angle_dict = xd.util.extract_angle_parameters(ds)\n",
    "    start_ang = angle_dict[\"start_angle\"]\n",
    "    stop_ang = angle_dict[\"stop_angle\"]\n",
    "    direction = angle_dict[\"direction\"]\n",
    "    ds = xd.util.remove_duplicate_rays(ds)\n",
    "    az = len(np.arange(start_ang, stop_ang))\n",
    "    ar = np.round(az / len(ds.azimuth.data), 2)\n",
    "    tolerance = ar if not tolerance else tolerance\n",
    "    ds = xd.util.reindex_angle(\n",
    "        ds, \n",
    "        start_ang,  \n",
    "        stop_ang, \n",
    "        ar, \n",
    "        direction, \n",
    "        method=\"nearest\", \n",
    "        tolerance=tolerance, **kwargs\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the [`Xarray.open_mfdataset`](https://docs.xarray.dev/en/stable/generated/xarray.open_mfdataset.html) method to open all `nc` files simultaneously. We can iterate over each sweep and concatenate them along the `volume_time` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the sweeps within each nc file\n",
    "sweeps = [\n",
    "        i[1:] for i in list(dt.groups) if i.startswith(\"/sweep\") if i not in [\"/\"]\n",
    "    ]\n",
    "sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sweep in sweeps:\n",
    "    root = {}\n",
    "    ds = xr.open_mfdataset(\n",
    "        local_files,\n",
    "        preprocess=fix_angle,\n",
    "        engine=\"cfradial1\",\n",
    "        group=sweep,\n",
    "        concat_dim=\"volume_time\",\n",
    "        combine=\"nested\",\n",
    "    ).xradar.georeference()\n",
    "    ds\n",
    "    root[f\"{sweep}\"] = ds\n",
    "    dtree = DataTree.from_dict(root)\n",
    "    \n",
    "    try:\n",
    "        dtree.to_zarr(\n",
    "            \"radar_ts.zarr\", \n",
    "            consolidated=True,\n",
    "        )\n",
    "    except ContainsGroupError:\n",
    "        dtree.to_zarr(\n",
    "            \"radar_ts.zarr\", \n",
    "            consolidated=True, \n",
    "            mode=\"a\", \n",
    "        )\n",
    "    del dtree, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our new radar-time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = xr.backends.api.open_datatree(\n",
    "    \"radar_ts.zarr\",\n",
    "    consolidated=True,\n",
    "    chunks={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created a Analysis-Ready Cloud-Optimezed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We discussed the concept of Analysis-Ready Cloud-Optimezed (ARCO) datasets, emphasizing the importance of datasets that are pre-processed, clean, and well-organized. Leveraging the Climate and Forecast (CF) format-based FM301 hierarchical tree structure, endorsed by the World Meteorological Organization (WMO), we developed an open data model to arrange, manage, and store radar data in cloud-storage buckets efficiently. The ultimate goal of radar ARCO data is to streamline the data science process, making datasets immediately usable without the need for extensive preprocessing.\n",
    "\n",
    "### What's next?\n",
    "Now, we can explore some quantitavite precipitation estimation (QPE) and quasy-vertical profiles (QVP) demos in the QPE-QVPs notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    " - [Xradar](https://docs.openradarscience.org/projects/xradar/en/stable/index.html)\n",
    " - [Radar cookbook](https://github.com/ProjectPythia/radar-cookbook)\n",
    " - [Py-Art landing page](https://arm-doe.github.io/pyart/)\n",
    " - [Wradlib landing page](https://docs.wradlib.org/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
